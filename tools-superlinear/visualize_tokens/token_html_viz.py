#!/usr/bin/env python3
"""
Create HTML visualization of token probabilities.

This script creates an HTML visualization of token probabilities from
the JSON token data generated by llama.cpp.

Two modes available:
- absolute: shows 1/p where p is the absolute probability
- relative: shows 1/(p/max(candidates)) where p is the token's probability
"""

import argparse
import os
import sys
import json
import html

import matplotlib.colors as mcolors
from loguru import logger

# Import the token loading function
from utils import load_jsonl


def get_color_for_score(score, max_score=10.0):
    """Get a color for a score based on its value - simple green with varying intensity."""
    # Clamp score to max_score
    score = min(score, max_score)
    
    # Normalize score to 0-1 range
    intensity = score / max_score
    
    # Simple green with varying intensity (0-255)
    # Higher score = BRIGHTER green (not darker)
    green_value = 255 - int(50 + 205 * intensity)  # Range from dark green (50) to bright green (255)
    
    # Return hex color
    return f"#00{green_value:02x}00"

def create_html_visualization(tokens, output_file, mode='absolute', token_map_file=None):
    """Create an HTML visualization of token probabilities."""
    # Process tokens
    token_data = []
    
    # Load token map if available
    token_text_map = {}
    if token_map_file and os.path.exists(token_map_file):
        try:
            with open(token_map_file, 'r') as f:
                for line in f:
                    try:
                        token_info = json.loads(line.strip())
                        token_text_map[token_info['token_id']] = token_info['text']
                    except json.JSONDecodeError:
                        continue
            logger.info(f"Loaded {len(token_text_map)} tokens from token map file")
        except Exception as e:
            logger.error(f"Error loading token map: {e}")
            raise RuntimeError(f"Failed to load token map file: {e}")
    else:
        logger.warning(f"Token map file not found or not specified: {token_map_file}")
        logger.warning("Will use token IDs as fallback")

    # Track missing tokens
    missing_tokens = set()
    
    for token in tokens:
        token_id = token.get('selected_token_id')
        prob = token.get('selected_probability')
        
        if token_id is None or prob is None:
            continue
            
        # Calculate score based on mode
        if mode == 'relative':
            # Get max probability from candidates
            candidates = token.get('tokens', [])
            if candidates:
                max_prob = max(t.get('probability', 0) for t in candidates)
                score = 1.0 / (prob / max_prob) if max_prob > 0 else float('inf')
            else:
                score = 1.0
        else:  # absolute mode
            score = 1.0 / prob if prob > 0 else float('inf')
            
        # Get color for score
        color = get_color_for_score(score)
        
        # Get token text - use fallback if not in map
        if token_id in token_text_map:
            token_text = token_text_map[token_id]
        else:
            token_text = f"<T{token_id}>"
            missing_tokens.add(token_id)
        
        token_data.append({
            'token_id': token_id,
            'probability': prob,
            'score': score,
            'color': color,
            'text': token_text
        })
    
    # Create HTML
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>Token Probability Visualization</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                margin: 20px;
            }
            .token-container {
                display: flex;
                flex-wrap: wrap;
                margin-top: 20px;
            }
            .token {
                display: inline-block;
                padding: 5px 10px;
                margin: 2px;
                border-radius: 3px;
                font-family: monospace;
                font-weight: bold;
                white-space: pre;
                min-width: 20px;
                text-align: center;
            }
            
            /* Style for whitespace tokens to make them visible */
            .whitespace-token {
                border: 1px dashed #999;
            }
            
            /* Style for newline tokens */
            .newline-token {
                display: block;
                margin: 5px 0;
                width: 100%;
                height: 1px;
                background-color: #ccc;
            }
            .tooltip {
                position: relative;
                display: inline-block;
            }
            .tooltip .tooltiptext {
                visibility: hidden;
                width: 200px;
                background-color: #555;
                color: #fff;
                text-align: left;
                border-radius: 6px;
                padding: 5px;
                position: absolute;
                z-index: 1;
                bottom: 125%;
                left: 50%;
                margin-left: -100px;
                opacity: 0;
                transition: opacity 0.3s;
                font-size: 12px;
            }
            .tooltip:hover .tooltiptext {
                visibility: visible;
                opacity: 1;
            }
            .legend {
                margin-top: 20px;
                padding: 10px;
                border: 1px solid #ddd;
                border-radius: 5px;
                background-color: #f9f9f9;
            }
            .legend-item {
                display: inline-block;
                width: 20px;
                height: 20px;
                margin-right: 5px;
                vertical-align: middle;
            }
        </style>
    </head>
    <body>
        <h1>Token Probability Visualization - """ + mode.capitalize() + """ Mode</h1>
        <p>This visualization shows tokens colored by their probability scores using """ + mode + """ mode.</p>
        <p><strong>Mode:</strong> """ + ("Absolute (1/p)" if mode == 'absolute' else "Relative (1/(p/max_p))") + """</p>
        
        <div class="token-container">
    """
    
    # Add legend
    html_content += """
    <div class="legend">
        <h3>Legend</h3>
        <p>Green intensity represents token scores (1/probability):</p>
        <div style="display: flex; align-items: center; margin-top: 10px; margin-bottom: 15px;">
            <span style="display: inline-block; width: 20px; height: 20px; background-color: #003200;"></span>
            <span style="margin: 0 5px;">→ Low score (high probability)</span>
            <span style="display: inline-block; width: 20px; height: 20px; background-color: #00ff00;"></span>
            <span style="margin: 0 5px;">→ High score (low probability)</span>
        </div>
        
        <div style="display: flex; align-items: center; margin-top: 5px;">
            <span style="display: inline-block; width: 300px; height: 20px; background: linear-gradient(to right, #003200, #00ff00);"></span>
            <span style="margin-left: 10px;">Score gradient (low to high)</span>
        </div>
    </div>
"""
    
    # Add tokens
    for i, token in enumerate(token_data):
        token_id = token['token_id']
        prob = token['probability']
        score = token['score']
        color = token['color']
        token_text = token.get('text', f"T{token_id}")
        
        # Determine text color based on background color brightness
        # Use white text for dark backgrounds, black text for light backgrounds
        r, g, b = mcolors.hex2color(color)
        brightness = (r * 299 + g * 587 + b * 114) / 1000
        text_color = "#FFFFFF" if brightness < 0.5 else "#000000"
        
        # Process token text for display
        display_text = token_text
        is_whitespace = False
        is_newline = False
        
        # Handle special whitespace characters
        if token_text == ' ' or token_text == '\t':
            display_text = '␣' if token_text == ' ' else '→'
            is_whitespace = True
        elif token_text == '\n':
            display_text = '⏎'
            is_newline = True
        
        # Add CSS classes based on token type
        token_classes = "token"
        if is_whitespace:
            token_classes += " whitespace-token"
        if is_newline:
            token_classes += " newline-token"
        
        html_content += f"""
        <div class="tooltip">
            <span class="{token_classes}" style="background-color: {color}; color: {text_color};">{html.escape(display_text)}</span>
            <span class="tooltiptext">
                Token ID: {token_id}<br>
                Text: {html.escape(repr(token_text)[1:-1])}<br>
                Probability: {prob:.6f}<br>
                Score: {score:.2f}
            </span>
        </div>"""
    
    # Close HTML
    html_content += """
    </div>
</body>
</html>
"""
    
    # Report missing tokens
    if missing_tokens:
        logger.warning(f"Missing {len(missing_tokens)} tokens in the token map: {sorted(list(missing_tokens))}")
    
    # Write HTML to file
    with open(output_file, 'w') as f:
        f.write(html_content)
    
    logger.success(f"HTML visualization saved to {output_file}")
    return True

def main():
    """Main function."""
    parser = argparse.ArgumentParser(description='Create HTML visualization of token probabilities')
    parser.add_argument('input_file', help='Input JSONL file with token data')
    parser.add_argument('--output', '-o', help='Output HTML file base name', default='token_viz')
    parser.add_argument('--token_map', '-t', help='Input JSONL file with token map data')
    args = parser.parse_args()
    
    # Load token data
    try:
        tokens = load_jsonl(args.input_file)
        if not tokens:
            logger.error(f"No token data found in {args.input_file}")
            return 1
    except Exception as e:
        logger.error(f"Error loading token data: {e}")
        return 1
    
    # Create visualizations for both modes
    try:
        # Absolute mode
        abs_output = f"{args.output}_absolute.html"
        create_html_visualization(tokens, abs_output, 'absolute', args.token_map)
        logger.success(f"Absolute mode visualization saved to {abs_output}")
        
        # Relative mode
        rel_output = f"{args.output}_relative.html"
        create_html_visualization(tokens, rel_output, 'relative', args.token_map)
        logger.success(f"Relative mode visualization saved to {rel_output}")
    except Exception as e:
        logger.error(f"Error creating visualization: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 